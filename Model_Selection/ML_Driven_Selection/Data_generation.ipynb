{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this python notebook is used to generate the data for the model selection project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "'''Uncomment this line to import the training functions'''\n",
    "# from some_module import train_sarima, train_xgboost, train_prophet, train_lstm  # Assume you have these functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(df, target_col):\n",
    "    \"\"\"\n",
    "    Train all models and evaluate their performance.\n",
    "    Returns the best model name based on RMSE.\n",
    "    \"\"\"\n",
    "    # Train models\n",
    "    predictions = {\n",
    "        \"SARIMA\": train_sarima(df, target_col),\n",
    "        \"XGBoost\": train_xgboost(df, target_col),\n",
    "        \"Prophet\": train_prophet(df, target_col),\n",
    "        \"LSTM\": train_lstm(df, target_col)\n",
    "    }\n",
    "    \n",
    "    # Compute RMSE for each model\n",
    "    rmse_scores = {model: mean_squared_error(df[target_col], pred, squared=False) for model, pred in predictions.items()}\n",
    "    \n",
    "    # Select the model with the lowest RMSE\n",
    "    best_model = min(rmse_scores, key=rmse_scores.get)\n",
    "    \n",
    "    return best_model, rmse_scores\n",
    "\n",
    "# Example: Apply to multiple datasets\n",
    "results = []\n",
    "for dataset in dataset_list:  # Assume you have multiple time series datasets\n",
    "    best_model, rmse_scores = evaluate_models(dataset, target_col=\"value\")\n",
    "    \n",
    "    # Extract features\n",
    "    features = extract_features(dataset, target_col=\"value\")  # Use the feature extraction function we discussed earlier\n",
    "    \n",
    "    # Store in labeled dataset\n",
    "    results.append(features + [best_model])  # Append the label\n",
    "\n",
    "# Convert to DataFrame\n",
    "columns = feature_names + [\"best_model\"]\n",
    "meta_learning_dataset = pd.DataFrame(results, columns=columns)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
