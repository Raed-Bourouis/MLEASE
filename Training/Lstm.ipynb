{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 2. Charger les données\n",
    "# Charger les données prétraitées\n",
    "df = pd.read_csv(\"../preprocessing/preprocessed_timeseries.csv\", parse_dates=True, index_col=0)\n",
    "\n",
    "# S'assurer que l'index est une colonne de type datetime\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "# Identifier les colonnes cibles (toutes sauf la date)\n",
    "target_columns = df.columns.tolist()\n",
    "\n",
    "# Dictionnaire pour stocker les prédictions\n",
    "forecast_results = {}\n",
    "\n",
    "# 3. Normalisation des données\n",
    "# LSTM fonctionne mieux avec des données normalisées entre 0 et 1 :\n",
    "scalers = {}\n",
    "scaled_data = {}\n",
    "\n",
    "for column in target_columns:\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data[column] = scaler.fit_transform(df[[column]])\n",
    "    scalers[column] = scaler\n",
    "\n",
    "# 4. Transformer les données en séquences pour LSTM\n",
    "def create_sequences(data, seq_length=12):\n",
    "    \"\"\"\n",
    "    Transforme les données en séquences pour le modèle LSTM.\n",
    "    Chaque séquence contient seq_length valeurs passées pour prédire la suivante.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "#seq_length: Nombre de pas de temps utilisés pour la prédiction\n",
    "detected_freq = pd.infer_freq(df.index)\n",
    "print(\"***\",detected_freq,\"***\")\n",
    "if detected_freq in [\"D\", \"B\"]:  # Quotidienne ou Business Days\n",
    "    seq_length = 10\n",
    "elif detected_freq in [\"MS\", \"M\"]:# \"justify your choices\"\n",
    "    seq_length = 12\n",
    "else:\n",
    "    seq_length = 1\n",
    "print(seq_length)\n",
    "# Dictionnaire pour stocker les séquences\n",
    "sequences = {}\n",
    "\n",
    "for column in target_columns:\n",
    "    X, y = create_sequences(scaled_data[column], seq_length)\n",
    "    sequences[column] = (X, y)\n",
    "\n",
    "# 5. Séparer les données en Train (80%) et Test (20%)\n",
    "train_size = int(0.8 * len(df))\n",
    "\n",
    "train_sequences = {}\n",
    "test_sequences = {}\n",
    "\n",
    "for column in target_columns:\n",
    "    X, y = sequences[column]\n",
    "    train_sequences[column] = (X[:train_size], y[:train_size])\n",
    "    test_sequences[column] = (X[train_size:], y[train_size:])\n",
    "\n",
    "# 6. Définir l'architecture du modèle LSTM\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(200, activation='relu', return_sequences=True, input_shape=input_shape),\n",
    "        LSTM(200, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# 7. Entraîner un modèle LSTM par colonne\n",
    "for column in target_columns:\n",
    "    print(f\"Training LSTM model for {column}...\")\n",
    "\n",
    "    X_train, y_train = train_sequences[column]\n",
    "    X_test, y_test = test_sequences[column]\n",
    "\n",
    "    # Construire et entraîner le modèle\n",
    "    model = build_lstm_model((seq_length, 1))\n",
    "    model.fit(X_train, y_train, epochs=200, batch_size=16, verbose=1)\n",
    "\n",
    "    # Faire des prédictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Inverser la normalisation\n",
    "    y_pred_rescaled = scalers[column].inverse_transform(y_pred)\n",
    "    y_test_rescaled = scalers[column].inverse_transform(y_test)\n",
    "\n",
    "    # Calculer l'erreur\n",
    "    mse = mean_squared_error(y_test_rescaled, y_pred_rescaled)\n",
    "    print(f\"MSE for {column}: {mse:.4f}\")\n",
    "\n",
    "    # Sauvegarder les résultats\n",
    "    forecast_results[column] = pd.DataFrame({\n",
    "        \"ds\": df.index[train_size + seq_length:],\n",
    "        \"yhat\": y_pred_rescaled.flatten()\n",
    "    })\n",
    "\n",
    "    # Visualisation\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(df.index[:train_size], df[column][:train_size], label=\"Train\")\n",
    "    plt.plot(df.index[train_size:], df[column][train_size:], label=\"Test\", color=\"orange\")\n",
    "    plt.plot(df.index[train_size + seq_length:], y_pred_rescaled, label=\"Forecast\", linestyle=\"dashed\", color=\"red\")\n",
    "    plt.title(f\"Prédictions LSTM pour {column}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Sauvegarder les prévisions\n",
    "for col, forecast in forecast_results.items():\n",
    "    forecast.to_csv(f\"forecast_lstm_{col}.csv\", index=False)\n",
    "\n",
    "print(\"Toutes les prédictions LSTM ont été enregistrées.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
