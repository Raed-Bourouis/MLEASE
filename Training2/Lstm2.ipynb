{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from sklearn.metrics import (mean_absolute_error,\n",
    "                             mean_absolute_percentage_error,\n",
    "                             mean_squared_error, r2_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping  # type: ignore\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint  # type: ignore\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout  # type: ignore\n",
    "from tensorflow.keras.models import Sequential, load_model  # type: ignore\n",
    "from tensorflow.keras.optimizers import Adam  # type: ignore\n",
    "from joblib import Parallel, delayed, parallel_backend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Charger les données\n",
    "# Charger les données prétraitées\n",
    "\n",
    "df = pd.read_csv(\"../datasets/Alcohol_Sales.csv\", parse_dates=True, index_col=0)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# S'assurer que l'index est une colonne de type datetime\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "# if len(df.columns) == 1 : df['target'] = df[df.columns[-1]]\n",
    "\n",
    "\n",
    "\n",
    "# Identifier les colonnes cibles (toutes sauf la date)\n",
    "target_column = df.columns[-1]\n",
    "\n",
    "feature_columns = [col for col in df.columns if col != target_column] if len(df.columns) > 1 else [target_column]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Normalisation des données\n",
    "# LSTM fonctionne mieux avec des données normalisées entre 0 et 1 :\n",
    "scalers = {}\n",
    "scaled_data = {}\n",
    "\n",
    "scalers = {}\n",
    "\n",
    "for column in df.columns:\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data[column] = scaler.fit_transform(df[[column]])\n",
    "    scaled_data[column] = scaled_data[column].flatten()\n",
    "    scalers[column] = scaler\n",
    "\n",
    "scaled_data = pd.DataFrame(scaled_data, index=df.index)\n",
    "scaled_data.reset_index(inplace=True)\n",
    "train_size = int(len(scaled_data) * 0.8)\n",
    "X_train = scaled_data.iloc[:train_size][feature_columns]\n",
    "y_train = scaled_data.iloc[:train_size][target_column]\n",
    "X_test = scaled_data.iloc[train_size:][feature_columns]\n",
    "y_test = scaled_data.iloc[train_size:][target_column]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
    "# scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# # Fit scaler on training data only\n",
    "# X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "# y_train_scaled = scaler_X.transform(pd.DataFrame(y_train))\n",
    "# # y_train_scaled = scaler_y.fit_transform(pd.DataFrame(y_train))\n",
    "\n",
    "# # Transform test data with the same scaler\n",
    "# X_test_scaled = scaler_X.transform(X_test)\n",
    "# y_test_scaled = scaler_X.transform(pd.DataFrame(y_test))\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 4. Transformer les données en séquences pour LSTM\n",
    "# def create_sequences(data, seq_length=12):\n",
    "#     sequences = []\n",
    "#     for i in range(len(data) - seq_length):\n",
    "#         seq = data[i:i+seq_length]\n",
    "#         sequences.append(seq)\n",
    "#     return np.array(sequences)\n",
    "\n",
    "# #seq_length: Nombre de pas de temps utilisés pour la prédiction\n",
    "# detected_freq = pd.infer_freq(df.index)\n",
    "# print(\"***\",detected_freq,\"***\")\n",
    "# if detected_freq in [\"D\", \"B\"]:  # Quotidienne ou Business Days\n",
    "#     seq_length = 10\n",
    "# elif detected_freq in [\"MS\", \"M\"]:# \"justify your choices\"\n",
    "#     seq_length = 12\n",
    "# else:\n",
    "#     seq_length = 1\n",
    "# print(seq_length)\n",
    "# # Dictionnaire pour stocker les séquences\n",
    "\n",
    "# X_train_seq = create_sequences(X_train, seq_length=seq_length)\n",
    "# y_train_seq = create_sequences(y_train, seq_length=seq_length)\n",
    "# X_test_seq = create_sequences(X_test, seq_length=seq_length)\n",
    "# y_test_seq = create_sequences(y_test, seq_length=seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(X, y, seq_length=12):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        Xs.append(X[i:i+seq_length])\n",
    "        ys.append(y[i + seq_length])  # Predict one step ahead\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "# Detect frequency to set sequence length dynamically\n",
    "detected_freq = pd.infer_freq(df.index)\n",
    "print(\"***\", detected_freq, \"***\")\n",
    "\n",
    "if detected_freq in [\"D\", \"B\"]:  # Daily or Business Days\n",
    "    seq_length = 10\n",
    "elif detected_freq in [\"MS\", \"M\"]:  # Monthly Start or Monthly\n",
    "    seq_length = 12\n",
    "else:\n",
    "    seq_length = 1\n",
    "\n",
    "print(\"Sequence length:\", seq_length)\n",
    "\n",
    "# Prepare the data (use .values to get numpy arrays)\n",
    "X_train_seq, y_train_seq = create_sequences(X_train.values, y_train.values, seq_length)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test.values, y_test.values, seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Hyperparameters\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 3)\n",
    "    units = trial.suggest_int('units', 32, 128)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        return_seq = (i < n_layers - 1)\n",
    "        if i == 0:\n",
    "            model.add(LSTM(units,activation='tanh', return_sequences=return_seq, input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
    "        else:\n",
    "            model.add(LSTM(units,activation='tanh', return_sequences=return_seq))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(units=1, activation='linear'))  # Regression\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='mse', metrics=['mse'])\n",
    "\n",
    "    # Callbacks\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=5, restore_best_weights=True)\n",
    "    pruning_callback = TFKerasPruningCallback(trial, \"val_loss\")\n",
    "\n",
    "    # Save best model of this trial\n",
    "    model_path = f\"BestModel.keras\"\n",
    "    checkpoint = ModelCheckpoint(model_path, monitor=\"val_loss\", save_best_only=True)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_seq, y_train_seq,\n",
    "        validation_data=(X_test_seq, y_test_seq),\n",
    "        epochs=100,\n",
    "        batch_size=16,\n",
    "        callbacks=[early_stopping, pruning_callback, checkpoint],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    return min(history.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=5)\n",
    "study = optuna.create_study(direction='minimize', pruner=pruner)\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(\"  Value: \", study.best_trial.value)\n",
    "print(\"  Params: \", study.best_trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Définir l'architecture du modèle LSTM\n",
    "def build_lstm_model():\n",
    "    model = Sequential([\n",
    "        LSTM(200, activation='relu', return_sequences=True, input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])),\n",
    "        LSTM(200, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    model.fit(X_train_seq, y_train_seq, epochs=200, batch_size=16, verbose=1)\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_lstm_model_2():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(50, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.fit(X_train_seq, y_train_seq, epochs=200, batch_size=16, verbose=1)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def build_optuna_lstm_model():\n",
    "    pruner = optuna.pruners.MedianPruner(n_warmup_steps=5)\n",
    "    study = optuna.create_study(direction=\"minimize\", pruner=pruner)\n",
    "    study.optimize(objective, n_trials=50)\n",
    "    best_params = study.best_params\n",
    "\n",
    "    model = Sequential()\n",
    "    for i in range(best_params[\"n_layers\"]):\n",
    "        return_seq = i < best_params[\"n_layers\"] - 1\n",
    "        if i == 0:\n",
    "            model.add(\n",
    "                LSTM(\n",
    "                    best_params[\"units\"],\n",
    "                    activation=\"relu\",\n",
    "                    return_sequences=return_seq,\n",
    "                    input_shape=(X_train_seq.shape[1], X_train_seq.shape[2]),\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            model.add(\n",
    "                LSTM(\n",
    "                    best_params[\"units\"], activation=\"relu\", return_sequences=return_seq\n",
    "                )\n",
    "            )\n",
    "        model.add(Dropout(best_params[\"dropout_rate\"]))\n",
    "\n",
    "    model.add(Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(best_params[\"learning_rate\"]), loss=\"mse\", metrics=[\"mse\"]\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train_seq,\n",
    "        y_train_seq,\n",
    "        validation_data=(X_test_seq, y_test_seq),\n",
    "        epochs=100,\n",
    "        batch_size=16,\n",
    "        # callbacks=[EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=5, restore_best_weights=True)],\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with parallel_backend(\"loky\"):    \n",
    "    models = Parallel(n_jobs=3)(\n",
    "        delayed(func)()\n",
    "        for func in [\n",
    "            build_lstm_model_2,\n",
    "            build_lstm_model,\n",
    "            # build_optuna_lstm_model\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "# model = build_lstm_model()\n",
    "# history = model.fit(\n",
    "#     X_train_seq, y_train_seq,\n",
    "#     epochs=100,\n",
    "#     batch_size=32,\n",
    "#     validation_split=0.2,\n",
    "#     callbacks=[early_stopping],\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "model = Sequential()\n",
    "for i in range(best_params['n_layers']):\n",
    "    return_seq = (i < best_params['n_layers'] - 1)\n",
    "    if i == 0:\n",
    "        model.add(LSTM(best_params['units'], activation='relu', return_sequences=return_seq, input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
    "    else:\n",
    "        model.add(LSTM(best_params['units'], activation='relu', return_sequences=return_seq))\n",
    "    model.add(Dropout(best_params['dropout_rate']))\n",
    "\n",
    "model.add(Dense(units=1, activation='linear'))\n",
    "\n",
    "model.compile(optimizer=Adam(best_params['learning_rate']), loss='mse', metrics=['mse'])\n",
    "\n",
    "model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    validation_data=(X_test_seq, y_test_seq),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    # callbacks=[EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=5, restore_best_weights=True)],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "train_loss = model.evaluate(X_train_seq, y_train_seq, verbose=0)\n",
    "test_loss = model.evaluate(X_test_seq, y_test_seq, verbose=0)\n",
    "print(f'Train Loss: {train_loss}')\n",
    "print(f'Test Loss: {test_loss}')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test_seq)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_rescaled = scalers[target_column].inverse_transform(y_test.values.reshape(-1, 1))  # For actual values\n",
    "y_pred_rescaled = scalers[target_column].inverse_transform(predictions)\n",
    "y_train_rescaled = scalers[target_column].inverse_transform(y_train.values.reshape(-1, 1))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_train.index, y_train_rescaled, label=\"Train\")\n",
    "plt.plot(y_test.index, y_test_rescaled, label=\"Test\", color=\"orange\")\n",
    "plt.plot(y_test[seq_length:].index, y_pred_rescaled.flatten(), label=\"Forecast\", linestyle=\"dashed\", color=\"red\")\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test_rescaled[seq_length:], y_pred_rescaled)\n",
    "mae = mean_absolute_error(y_test_rescaled[seq_length:],y_pred_rescaled )\n",
    "r2 = r2_score(y_test_rescaled[seq_length:],y_pred_rescaled)\n",
    "mape=mean_absolute_percentage_error(y_test_rescaled[seq_length:], y_pred_rescaled)\n",
    "\n",
    "print(f\"Mean Absolute Percentage Error: {mape}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rescaled"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
