{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données prétraitées\n",
    "df = pd.read_csv(\"../preprocessing/preprocessed_timeseries.csv\", parse_dates=True, index_col=0)\n",
    "\n",
    "# S'assurer que l'index est une colonne de type datetime\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "# Identifier les colonnes cibles (toutes sauf la date)\n",
    "target_column = df.columns[-1]\n",
    "\n",
    "feature_columns = [col for col in df.columns if col != target_column] if len(df.columns) > 1 else [target_column]\n",
    "\n",
    "# Dictionnaire pour stocker les prédictions\n",
    "forecast_results = {}\n",
    "type(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(\n",
    "    df, target_column=None, lags=3, rolling_windows=[], test_size=0.2, random_state=42\n",
    "):\n",
    "    df = df.copy()\n",
    "    lags = 3\n",
    "    if target_column is None:\n",
    "        target_column = df.columns[-1]\n",
    "\n",
    "    for column in feature_columns:\n",
    "        for lag in range(1, lags + 1):\n",
    "            df[f\"{column}_lag_{lag}\"] = df[column].shift(lag)\n",
    "        detected_freq = pd.infer_freq(df.index)\n",
    "        print(\"***\", detected_freq, \"***\")\n",
    "\n",
    "        rolling_windows = []\n",
    "        if detected_freq in [\"D\", \"B\"]:  # Quotidienne ou Business Days\n",
    "            rolling_windows = [7, 14, 30]\n",
    "        elif detected_freq in [\"MS\", \"M\"]:  # Mensuelle\n",
    "            rolling_windows = [3, 6, 12]\n",
    "        elif detected_freq in [\"YS\", \"Y\"]:  # Annuelle\n",
    "            rolling_windows = [2, 3, 5]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # Appliquer les moyennes mobiles pour detecter la saisonnalité\n",
    "        for window in rolling_windows:\n",
    "            df[f\"rolling_mean_{window}\"] = (\n",
    "                df[column].shift(1).rolling(window=window).mean()\n",
    "            )\n",
    "\n",
    "        # Supprimer les valeurs NaN générées par les décalages\n",
    "    df.dropna(inplace=True)\n",
    "    X = df.drop(columns=[target_column], axis=1)\n",
    "    y = df[target_column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, shuffle=False\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = create_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost_timeseries():\n",
    "    \"\"\"\n",
    "    Train XGBoost model for multivariate time series prediction\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input time series DataFrame\n",
    "    date_column : str, optional\n",
    "        Name of the date column\n",
    "    target_column : str or list, optional\n",
    "        Column(s) to predict\n",
    "    time_steps : int, optional\n",
    "        Number of previous time steps to use as features\n",
    "    test_size : float, optional\n",
    "        Proportion of data to use for testing\n",
    "    random_state : int, optional\n",
    "        Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict: Contains model, test data, predictions, and evaluation metrics\n",
    "    \"\"\"\n",
    "    # Create features and target\n",
    "\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Prepare DMatrix for XGBoost\n",
    "    dtrain = xgb.DMatrix(X_train_scaled, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test_scaled, label=y_test)\n",
    "    \n",
    "    # Define XGBoost parameters\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',  # Regression objective\n",
    "        'eval_metric': 'rmse',  # Root Mean Squared Error\n",
    "        'max_depth': 5,\n",
    "        'learning_rate': 0.1,\n",
    "        'n_estimators': 150\n",
    "    }\n",
    "    \n",
    "    # Train the model\n",
    "    model = xgb.train(\n",
    "        params, \n",
    "        dtrain, \n",
    "        num_boost_round=100,\n",
    "        evals=[(dtest, 'test')],\n",
    "        early_stopping_rounds=10,\n",
    "        verbose_eval=10\n",
    "    )\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(dtest)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test,predictions)\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'predictions': predictions,\n",
    "        'mse': mse,\n",
    "        'mae': mae,\n",
    "        \"r2\": r2,\n",
    "        'scaler': scaler\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train_xgboost_timeseries()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(y_train.index, y_train, label=\"Train\")\n",
    "plt.plot(y_test.index, y_test, label=\"Test\", color=\"orange\")\n",
    "plt.plot(y_test.index, results['predictions'], label=\"Forecast\", linestyle=\"dashed\", color=\"red\")\n",
    "plt.title(f\"Prédictions XGBoost pour {target_column}\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "df1=pd.DataFrame({target_column : results[\"predictions\"]}, index=y_test.index)\n",
    "df1.to_csv(f\"forecast_xgboost_{target_column}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"r2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OldXGBoost(df, target_columns):    \n",
    "    for column in target_columns:\n",
    "        print(f\"Training XGBoost model for {column}...\")\n",
    "\n",
    "        # Créer les features\n",
    "        data = create_features(df, column)\n",
    "\n",
    "        # Séparer les features (X) et la cible (y)\n",
    "        X = data.drop(columns=[column])\n",
    "        y = data[column]\n",
    "\n",
    "        # Séparer Train/Test (80% - 20%)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "        # Entraîner le modèle XGBoost\n",
    "        model = xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=100, learning_rate=0.1)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Faire des prédictions\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculer l'erreur\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        print(f\"MSE for {column}: {mse:.4f}\")\n",
    "\n",
    "        # Sauvegarder les résultats\n",
    "        forecast_results[column] = pd.DataFrame({\"ds\": X_test.index, \"yhat\": y_pred})\n",
    "\n",
    "        # Visualisation\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(y_train.index, y_train, label=\"Train\")\n",
    "        plt.plot(y_test.index, y_test, label=\"Test\", color=\"orange\")\n",
    "        plt.plot(y_test.index, y_pred, label=\"Forecast\", linestyle=\"dashed\", color=\"red\")\n",
    "        plt.title(f\"Prédictions XGBoost pour {column}\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    # Sauvegarder les prévisions\n",
    "    for col, forecast in forecast_results.items():\n",
    "        forecast.to_csv(f\"forecast_xgboost_{col}.csv\", index=False)\n",
    "\n",
    "    print(\"Toutes les prédictions XGBoost ont été enregistrées.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
